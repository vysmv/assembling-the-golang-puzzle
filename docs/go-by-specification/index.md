# Go по спецификации

Привет всем заглянувшим.

В этом видео я каснусь темы спецификации.
Каждому программисту на Go время от времени придется обращаться к спеке. 
А значит есть смысл проработать ее один раз, чтобы заложить корректный фундамет и понять как с ней работать в будущем.
Ну что же...в путь. 

## Введение

Первое, что я вынес из спецификации, — это формальное определение языка от его разработчиков.
Думаю, это стоит вынести отдельно, так как именно здесь зафиксировано то, чего от языка следует ожидать.

Go — язык общего назначения, спроектированный с оглядкой на системное программирование. Он строго типизирован, использует сборщик мусора и явно поддерживает конкурентное программирование. Программы строятся из пакетов; свойства пакетов позволяют эффективно управлять зависимостями.

От себя я лишь расставлю акценты.

Это:

Язык общего назначения
→ не DSL и не нишевый инструмент

Системное программирование как контекст проектирования
→ не «низкоуровневый», а ориентированный на системы

Строгая типизация + сборщик мусора
→ сознательное сочетание, а не компромисс

Явная поддержка конкурентности
→ не как библиотека, а часть модели языка

Плюс:
пакеты как фундамент

## Как читать спецификацию (Обозначение)

Далее в разделе "Обозначение" нам говорят - синтаксис языка описан при помощи EBNF.

EBNF (Extended Backus–Naur Form) — это:

- формальный способ описывать синтаксис языков,

- стандарт де-факто для спецификаций.

> Важно:
>
> EBNF — это не Go и не код вообще.
> Это метаязык который применили для описания синтаксиса Go.

Тут же нам приводят пример того как описана спецификация:
Syntax      = { Production } .
Production  = production_name "=" [ Expression ] "." .
Expression  = Term { "|" Term } .
Term        = Factor { Factor } .
Factor      = production_name | token [ "…" token ] | Group | Option | Repetition .
Group       = "(" Expression ")" .
Option      = "[" Expression "]" .
Repetition  = "{" Expression "}" .

Syntax = { Production } . — Это значит, что вся спецификация (Syntax) — это список из повторяющихся правил (Production). Фигурные скобки {} означают, что правил может быть сколько угодно (от 0 до n). Вариант «0 правил» технически возможен по правилам EBNF, но на практике это просто формальное описание того, что книга состоит из глав-правил.
Но нам по сути нужно запомнить только результат этого описания — то есть работу операторов:

- A B → A потом B
- A | B → либо A, либо B
- [ A ] → A может быть, а может не быть
- { A } → A может повторяться
- "if" → буквально слово if
- A … B означает выбор любого символа из диапазона от A до B. Например, decimal_digit = "0" … "9"
- ... → это просто обозначение и тд.

Главный вывод для работы: Когда мы увидим в спецификации строку вроде: 
SliceType = "[" "]" ElementType .
То мы понимаем её структуру:
1. Это Production (правило).
2. SliceType — это имя (нетерминал).
3. "[" и "]" — это терминалы (пишем их в коде как есть).
4. ElementType — это ссылка на другое правило (нетерминал).
5. . в конце — это просто маркер конца правила

Также в спецификации важно понимать, является ли слово «конечным» или оно само состоит из других правил.
Для ориентации можно использовать такие правила:
- CamelCase (например, Type): Это нетерминал (ссылка). Увидев такое слово, мы должны понимать: «Это не просто текст, у этого слова есть свое правило описания выше или ниже по тексту».
- lowercase (например, identifier): Это лексический токен. Самый мелкий кирпичик, который обычно описывается через символы. Они также являются терминалами. Просто в Спецификации их разделяют: слова в кавычках — это символы, которые мы пишем «как есть», а строчные имена — это правила для самых мелких кирпичиков (идентификаторов, чисел), которые уже нельзя разбить на другие правила Go.
- "текст" в кавычках: Это терминал. То, что мы буквально печатаем в редакторе (например, func, struct, {).

Вывод: Если мы видим в правиле CamelCase, то не можем просто написать это слово в коде — нам нужно найти правило для этого слова и посмотреть, из чего оно состоит.

> **Дополнительно**
>
> Почему «терминал»?
> Слово пришло из теории формальных языков и лингвистики.
> - Терминал (terminal) — это «конечная станция» или «тупик». Это то, что ты буквально пишешь в коде: буквы, цифры или знаки. Его нельзя разложить на что-то еще. Например, "if" или "+" — это терминалы.
> - Нетерминал (non-terminal) — это ссылка, которую нужно «раскрыть» дальше. Она написана в CamelCase. Например, Type — это нетерминал, потому что за ним стоит еще одно правило, объясняющее, какие типы бывают.
>
> Итог: Терминал — это «конечный символ», нетерминал — это «название правила».

И в завершении нюанс про маркеры версий ([Go 1.xx]): В Спеке часто встречаются пометки вроде [Go 1.18]. Это критически важно: они указывают, что данная возможность (например, дженерики или оператор ~) появилась не сразу, а в конкретной версии языка. 

В общем, я не хочу больше теоретизировать на эту тему, а просто посмотрим как это проявится на практике чтения спецификации. 

## Представление исходного кода (Source code representation)

Ключевые аспекты:
1. Единый стандарт: UTF-8
Весь исходный код Go — это текст в кодировке UTF-8. 
Это значит, что с компилятор ожидает именно этот формат. Это позволяет использовать любые Unicode-символы, но с важной оговоркой: для идентификаторов (имен переменных) можно использовать не любой символ вообще (например, эмодзи нельзя), а только те, что относятся к категориям Unicode «Letters» (буквы) и «Digits» (цифры).
2. Важный нюанс: Отсутствие канонизации.
Go не канонизирует (не исправляет и не объединяет) наш текст.
Что это значит на практике: В Unicode один и тот же сложный символ (например, ä или й) можно записать двумя способами:
- Как один готовый символ (одна «кодовая точка»). Это так называемые Precomposed (предварительно составленные): один код (code point) для ä (U+00E4).
- Как комбинацию базовой буквы и отдельного знака акцента (две «кодовые точки»). Combining sequences (комбинированные): два кода — буква `a` `(U+0061)` + символ диерезиса `¨` `(U+0308)`. Визуально они идентичны, но для системы это разные данные.

Смысл для разработчика: Для Go это разные символы. Если вы назовете переменную первым способом, а попытаетесь вызвать ее в коде, введя вторым, компилятор выдаст ошибку, так как для него это два разных идентификатора.
Опора для понимания: Визуальное сходство знаков не означает их программную идентичность. Мы должны быть уверены, что используем одинаковый ввод.

На примере это будет выглядет так:
```go
package main

import "fmt"

func main() {
	s1 := "\u00e4"   // "ä" как одна кодовая точка (U+00E4)
	s2 := "a\u0308"  // "ä" как комбинация "a" (Перед обратным слешем) (U+0061) + "¨" (U+0308)

	s3 := "ä"
	s4 := "ä"

	s5 := "ä"
	s6 := "ä"
	
	fmt.Println(s1 == s2) // false
	fmt.Println(len(s1))  // 2 (байта в UTF-8)
	fmt.Println(len(s2))  // 3 (байта в UTF-8)
	fmt.Println(s1)  // ä
	fmt.Println(s2)  // ä

	if s3 == s4 {
		fmt.Println("s3 and s4 are equal")
	} else {
		fmt.Println("s3 and s4 are not equal")
	}

	if s5 == s6 {
		fmt.Println("s5 and s6 are equal")
	} else {
		fmt.Println("s5 and s6 are not equal")
	}

	/*If such situations arise, it is worth comparing the sizes of the strings in bytes.*/
	if len(s3) != len(s4) {
		fmt.Println("the number of bytes is different")
	}
}
```
У нас есть код в котором мы обьявляем переменные s1 и s2 как кодовые точки.
Где s1 это "ä" символ `a` с диерезисом, как одна кодовая точка (U+00E4).
А в s2 `ä` как комбинация `a` (Перед обратным слешем) с кодом (U+0061) + `¨` ( символ диерезис (dieresis)) с кодом (U+0308).

Далее мы видим инициализацию s3 и s4.
Инициализируем их визуально одинаковыми строками с символом `ä` + с диерезисом.

И тоже самое делаем для переменных s5 и s6.

А после этого мы выполняем сравнение s3 и s4 и s5 и s6.
И еще одно сравнение s1 и s2 на кол-во байт.

Казаось бы в чем смысл этого странного примера?

А смысл в том, что если мы запустим код, то увидим что:
s1 == s2 это false
s1 это 2 байта
s2 это 3 байта
внешне s1 и s2 одинаковы

Далее видим, что s3 и s4 не равны
А s5 и s6 равны
И также видим что кол-во байт не равну для s1 и  s2.

То есть мы можем сталкнуться с ситуацией когда строки визуально одинаковы но не равны, и при этом видеть в другом месте что они равны. 
И если вдруг возникает такая ситуация, то выяснить в чем причина нужно имено через разницу строк в байтах. То есть для Go символы это именно кодовые точки Unicode и не важно как символы выглядят на печати, а также то что ответственность за корректность в этом вопросе лежит на программисте а не на компиляторе.

3. Правила формирования идентификаторов (например имена переменных или функций)
• Регистрозависимость: Заглавные и строчные буквы — это всегда разные символы (напр. A ≠ a).
• Специальная роль подчеркивания: Символ _ для Go официально считается строчной буквой. Это позволяет использовать его в начале и внутри имен.
• Цифры: Используются только стандартные арабские цифры (0-9).

Итог раздела: Go дает огромную свободу в использовании языков, но перекладывает ответственность за чистоту и единообразие текста на разработчика.
Это понимание того, «из чего сделан текст», позволяет нам перейти к Lexical elements — правилам, по которым этот текст разбивается на смысловые части (токены).

## Lexical elements — Лексические элементы

### Comments 

Первым пунктом нам сообщают, что в Go существует две формы комментариев:
- Строчные (Line comments): начинаются с последовательности // и заканчиваются в конце строки.
- Общие (General comments): начинаются с /* и заканчиваются первым встреченным */

Это распространенная практика.
Единственный нюанс который стоит положить в заметку это то, что в Go автоматически добавляет `;` после литералов или имен переменных, если за ними следует «новая строка».

Разница между комментариями в том, что `//` всегда считается новой строкой, а `/* */` (без переносов внутри) считается пробелом.

Это не то чтобы ключевой момент но например в этих двух случаях, есть разница
```go
// Скомпилируется: /* */ работает как пробел
f := complex(1.0 /* real */, 2.0) 

// ОШИБКА: // сработает как newline и вставит ";" после 1.0
// f := complex(1.0 // real , 2.0) 
``` 

### Tokens 

Далее спецификация сообщает нам, что Токены (лексемы) — это «словарь» языка Go.

Они делятся на 4 класса:
- Идентификаторы (имена переменных, функций и т.д.).
- Ключевые слова (зарезервированные слова вроде func или package).
- Операторы и пунктуация (знаки вроде +, :=, {).
- Литералы (фиксированные значения: числа, строки).

###  Semicolons 

Тут важно понять не «как именно вставляются ;», а где нельзя переносить строку. Всё остальное — детали реализации лексера.
В Go перенос строки это потенциальная `;`, если он идет после:
• Идентификатор (имя переменной, функции и т.д.).
• Литерал (число, строка, руна).
• Ключевые слова: break, continue, fallthrough или return.
• Операторы и пунктуация: ++, --, ), ] или }.

Например если сделать перенос перед else:
```go
if x > 0 {
    foo()
}
else {
    bar()
}
```
То для компилятора это будет:
```go
if x > 0 {
    foo()
};
else { ... }
```

###  Identifiers 

Тут можно коротко отметить идентификатор — это имя, которым мы обозначаем сущности программы
(переменные, типы и т.п.).

идентификатор:

- состоит из букв и цифр
- обязан начинаться с буквы

###  Keywords 

Основные выводы - Ключевые слова нельзя использовать как идентификаторы. 
Нельзя написать:
```go
var func int
type for struct {}
```
Вот полный список ключевых слов:
break        default      func         interface    select
case         defer        go           map          struct
chan         else         goto         package      switch
const        fallthrough  if           range        type
continue     for          import       return       var

Вот полный список опрераторов и пунктуации:
+    &     +=    &=     &&    ==    !=    (    )
-    |     -=    |=     ||    <     <=    [    ]
*    ^     *=    ^=     <-    >     >=    {    }
/    <<    /=    <<=    ++    =     :=    ,    ;
%    >>    %=    >>=    --    !     ...   .    :
     &^          &^=          ~

### Integer literals/Целочисленные литералы

Смысловое резюме
В Go literal — это синтаксическая форма записи константного значения.
Спецификация языка выделяет ровно пять категорий литералов:

- Integer literals
- Floating-point literals
- Imaginary literals
- Rune literals
- String literals

Это именно классификация синтаксиса, а не типов.

Дам немного больше контекста, чтобы убрать потенциальную путаницу.
В Go существует пять синтаксических форм литералов, которыми записываются константные значения.

Таким образом, программист располагает ограниченным набором форм записи значений. Эти значения могут присваиваться переменным или константам.
Отдельно от литералов в языке существует множество типов. Через выбор типа программист задаёт контекст использования значения — то есть определяет, как компилятор будет с ним работать.

В частности, тип определяет представление значения в памяти (в случае переменных), а также набор допустимых операций и правил преобразования.

Целочисленный литерал — это последовательность цифр, представляющая константу. 
Go поддерживает четыре системы счисления, которые определяются префиксом:

- Десятичная: без префикса (например, 42). Число 0 само по себе — это десятичный ноль.
- Двоичная: 0b или 0B.
- Восьмеричная: 0o, 0O или просто 0.
- Шестнадцатеричная: 0x или 0X. Буквы a-f (или A-F) обозначают значения 10–15.

Для удобства чтения можно использовать символ подчеркивания _ между цифрами или после префикса (например, 1_000 или 0x_ff), это не меняет значение числа.

И давайте посмотрим как читать синтаксические правила EBNF.

//Целое число может быть либо десятичным, либо двоичным и т.д
int_lit        = decimal_lit | binary_lit | octal_lit | hex_lit .


decimal_lit    = "0" | ( "1" … "9" ) [ [ "_" ] decimal_digits ] .
binary_lit     = "0" ( "b" | "B" ) [ "_" ] binary_digits .
octal_lit      = "0" [ "o" | "O" ] [ "_" ] octal_digits .
hex_lit        = "0" ( "x" | "X" ) [ "_" ] hex_digits .

decimal_digits = decimal_digit { [ "_" ] decimal_digit } .
binary_digits  = binary_digit { [ "_" ] binary_digit } .
octal_digits   = octal_digit { [ "_" ] octal_digit } .
hex_digits     = hex_digit { [ "_" ] hex_digit } .